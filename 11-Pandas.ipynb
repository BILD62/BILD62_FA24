{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas\n",
    "In this notebook, we'll encounter a very useful package for scientific computing in Python: Pandas. We can think of Pandas as \"numpy with labels\". This package is especially useful for data science and biology for a few reasons:\n",
    "* Great for real-world, heterogeneous data\n",
    "* Similar to Excel spreadsheets (but way faster!)\n",
    "* Smartly deals with missing data\n",
    "\n",
    "### At the end of this notebook, you'll be able to:\n",
    "* Create & manipulate Pandas dataframes\n",
    "* Load a tabular file of genetic data into a Pandas dataframe\n",
    "* Index and subset Pandas dataframes\n",
    "* Generate descriptive statistics for Pandas dataframes\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing packages\n",
    "\n",
    "Before we can pandas, we need to import it. The convention is to import `pandas` as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "\n",
    "# Use whos 'magic command' to see available modules\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create and Manipulate Dataframes \n",
    "The two data structures of Pandas are the `Series` and the `DataFrame`. A `Series` is a one-dimensional onject similar to a list. A `DataFrame` can be thought of as a two-dimensional numpy array or a collection of `Series` objects. Series and dataframes can contain multiple different data types such as integers, strings, and floats, similar to an Excel spreadsheet. Pandas also supports `string` lables unlike numpy arrays which only have numeric labels for their rows and columns. For a more in depth explanation, please visit the [Introduction to Data Structures](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html) section in the Pandas User Guide. \n",
    "\n",
    "You can create a Pandas dataframe by inputting dictionaries into the Pandas function `pd.DataFrame()`, by reading files, or through functions built into the Pandas package. The function [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) reads a comma- or tab-separated file and returns it as a `dataframe`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a data from a dictionary\n",
    "\n",
    "Below, we'll create a dataframe from a dictionary. Since this is quite a bit to fit into one cell, we're also using a trick where we use a pair of open parentheses to tell Python to *ignore* the line breaks here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "students = (\n",
    "  {'FIRST_NAME': ['Daniel', 'Ben', 'Kavita', 'Linda',\n",
    "                  'Omar','Jane', 'Felicia', 'Rachel',\n",
    "                  'Bob'],\n",
    "   'LAST_NAME': ['Smith', 'Leibstrom', 'Kanabar', 'Thiel',\n",
    "                 'Reichel', 'OConner', 'Rao', 'Crock',\n",
    "                 'McDonald'],\n",
    "   'YEAR': [1, 1, 1, 4, 2, 2, 3, 1, 1],\n",
    "   'HOME_STATE': ['NY', 'NY', 'PA', 'CA', 'OK', 'HI',\n",
    "                  'NY','FL', 'FL'],\n",
    "   'AGE': [18, 19, 19, 22, 21, 19, 20, 17, 18],\n",
    "   'CALC_101_FINAL': [90, 80, None, 60, 70, None, None,\n",
    "                      None, 98],\n",
    "   'ENGLISH_101_FINAL': [80, None, None, 40, 50, None,\n",
    "                         None, 60, 65]} )\n",
    "\n",
    "# Create the dataframe from our dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a list of all of the students' last names using the following notation: `df['column_name']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access LAST_NAME column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One column of the dataframe is a **series**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check type of column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a file example\n",
    "Below we will create a dataframe by reading the file `brainarea_vs_genes_exp_w_reannotations.tsv` which contains information on gene expression accross multiple brain areas. we'll use the `read_csv` function to import our gene expression data as a DataFrame.\n",
    "\n",
    ">**About this dataset:**\n",
    "This dataset was created by Derek Howard and Abigail Mayes for the purpose of accelerating advances in data mining of open brain transcriptome data for polygenetic brain disorders. The data comes from normalized microarray datasets of gene expression from 6 adult human brains that was released by the Allen Brain Institute and then processed into the dataframe we will see below. For more information on this dataset please visit the <a href = \"https://github.com/derekhoward/HBAsets\"> HBAsets repository</a>. \n",
    "\n",
    "Below, we'll use the `pandas.read_csv` function to import our gene expression data as a **data frame**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the list of lists as a data frame\n",
    "# Note \"delimiter\" from loadtxt is \"sep\" here\n",
    "gene_df = pd.read_csv('Data/brainarea_vs_genes_exp_w_reannotations.tsv',sep='\\t')\n",
    "\n",
    "#Show the first five rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, the first column  of information above, called the **index**, just contains a list of numbers. We can reassign the row labels by using the method `set_index()`. We can choose any column in our present dataframe to be the row values. Let's assign the row lables to be the `gene_symbol` and reassign the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = 'gene_symbol'\n",
    "gene_df = gene_df.set_index(row_index)\n",
    "gene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would help to know what information is in our dataset. In other words, what is across the columns at the top? We can get a list by accessing the `columns` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the columns of our dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing in Pandas works slightly different than in NumPy. Similar to a dictionary, we can index dataframes by their names. \n",
    "\n",
    "The syntax for indexing single locations in a dataframe is `dataframe.loc[row_label,column_label]`. To index an individual column, we use the shorthand syntax `dataframe.[column_label]`. To index an individual row, we use the syntax `dataframe.loc[row_label]`. To index by index #, we use the syntax `dataframe.iloc[index_number]`. Below are some examples on how to access rows, columns, and single values in our dataframe. For more information on indexing dataframes, visit the <a href = \"https://pandas.pydata.org/docs/user_guide/indexing.html#indexing\"> \"Indexing and selecting data\"</a> section in the Pandas User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column\n",
    "column = 'CA1 field'\n",
    "print('Gene expression values in CA1 field:')\n",
    "gene_df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single row\n",
    "row = 'A1BG'\n",
    "print('Gene expression of ', row, ' across brain regions:')\n",
    "gene_df.loc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an individual value \n",
    "print('Gene expression of A1BG in CA1 field:')\n",
    "gene_df.loc[row, column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple different columns, you can use a `list` of all your columns of interest as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe w/ only CA field entries \n",
    "CA_field_df = gene_df[['CA1 field', \n",
    "                       'CA2 field', \n",
    "                       'CA3 field', \n",
    "                       'CA4 field']]\n",
    "CA_field_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like NumPy arrays, we can subset our original dataframe to only include data that meets our criteria. Our dataframe has data on multiple different brain areas with many gene expression values. You can filter this dataframe using the following syntax:\n",
    "```\n",
    "new_df = original_df[original_df['Column of Interest'] == 'Desired Value']\n",
    "```\n",
    "In plain english, what this is saying is: save a dataframe from the original dataframe, where the original dataframe values in my Column of Interest are equal to my Desired Value. For more information on subsetting,  visit the <a href = \"https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\"> \"How do I select a subset of a DataFrame\"</a> section in the Pandas documentation. \n",
    "\n",
    "Below we will demonstrate how to execute this by taking a look at the `CA1 field` column in `gene_df`. We will create a dataframe from `gene_df` that only contains genes that showed a certain level of gene expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only genes that have an expression \n",
    "# value greater than 1.7 in 'CA1 field' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has many useful methods that you can use on your data, including `describe`, `mean`, and more. To learn more about all the different methods that can be used to manipulate and analyze dataframes, please visit the <a href = \"https://pandas.pydata.org/docs/user_guide/index.html\"> Pandas User Guide </a>. We will demonstrate some of these methods below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe` method returns descriptive statistics of all the columns in our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean` and `std` method return the mean and standard deviation of each column in the dataframe, respectfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try df.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try df.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging & joining dataframes\n",
    "\n",
    "Let's say we have two different dataframes and we would like to combine the two into one single dataframe. We can use either the `merge` or `join` Pandas methods in order to pull all of this data into one dataframe. \n",
    "\n",
    "![](http://www.datasciencemadesimple.com/wp-content/uploads/2017/09/join-or-merge-in-python-pandas-1.png)\n",
    "\n",
    "There are different types of joins/merges you can do in Pandas, illustrated <a href=\"http://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/\">above</a>. Here, we want to do an **inner** merge, where we're only keeping entries with indices that are in both dataframes. We could do this merge based on columns, alternatively.\n",
    "\n",
    "**Inner** is the default kind of join, so we do not need to specify it. And by default, join will use the 'left' dataframe, in other words, the dataframe that is executing the `join` method.\n",
    "\n",
    "If you need more information, look at the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html\">join</a> and <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\">merge</a> documentation: you can use either of these to unite your dataframes, though join will be simpler!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how to join two separate dataframe into one, unified dataframe. We start with one dataframe with only entries from the *temporal pole* and another dataframe with only entries from the CA fields of the hippocampus. We can then join the two dataframes together using the syntax `unified_df = df_1.join(df_2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe w/ only Temporal Pole entries \n",
    "temporal_pole_df = gene_df[['temporal pole, inferior aspect', \n",
    "                            'temporal pole, medial aspect', \n",
    "                            'temporal pole, superior aspect']]\n",
    "temporal_pole_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two dataframes\n",
    "df_1 = temporal_pole_df\n",
    "df_2 = CA_field_df\n",
    "\n",
    "unified_df = df_1.join(df_2)\n",
    "unified_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Group Task\n",
    "### *Does the number of neurons in the cortex scale with cortex size?*\n",
    "In this final task, we'll look at [this dataset](http://www.suzanaherculanohouzel.com/2015-h-h-et-al-bbe-database/) to figure out whether the number of neurons in the cortex scales with cortex size, and if this scaling is different for primates.  \n",
    "\n",
    "To complete this task, do the following steps in a separate notebook:\n",
    "\n",
    "1. Use `pd.read_csv()` to read in our comma-delimited file 'Data/species_brainmass_neurons.csv' and assign it to a dataframe called `brains_df`.\n",
    "2. Separate the dataframe into two dataframes: one that contains all of the primates (`primate_df`; 'Order' is Primata) and one that contains all of the data that are *not* from primates (`nonprimate_df`). **Hint**: You can subset the dataframe by using the syntax `brains_df[brains_df['Order']=='Primata']`.\n",
    "3. Using two separate, subsequent calls to `plt.scatter()` for primates and then non-primates, create a scatterplot with `cortex_mass` on the x axis and `neurons` on the y axis.\n",
    "6. Label your axes.\n",
    "7. (Optional) log scale your axes using `plt.xscale('log')` and `plt.yscale('log')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Additional resources\n",
    "See the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html) for a more in depth exploration of Pandas, and of course, the [Pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "rise": {
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
